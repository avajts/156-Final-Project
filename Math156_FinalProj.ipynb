{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eFOZBBXZb-yC"
   },
   "outputs": [],
   "source": [
    "# Import all packages here\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "!pip install kagglehub\n",
    "import kagglehub\n",
    "import os\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "!pip install tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, Dropout, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.python.keras.engine import data_adapter\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from PIL import Image\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XYFg_ySib-yD"
   },
   "source": [
    "###Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IHW_nwCob-yE",
    "outputId": "07d73fc2-0772-4b27-b8d4-5b28f4fdc2de"
   },
   "outputs": [],
   "source": [
    "# Download latest version\n",
    "kaggle_path = kagglehub.dataset_download(\"noamsegal/affectnet-training-data\") + '/'\n",
    "print(\"Path to dataset files:\", kaggle_path)\n",
    "\n",
    "# Import the labels.csv file as our dataset\n",
    "df = pd.read_csv(kaggle_path+\"/labels.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "4GxqJrFpd9LU",
    "outputId": "02e76d0a-d78f-4b58-f312-5f30cfc5c6c7"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TAx4sGVvb-yF"
   },
   "outputs": [],
   "source": [
    "# Define each unique emotion\n",
    "labels = df['label'].unique()\n",
    "\n",
    "def get_classes_distribution(df):\n",
    "  \"\"\"\n",
    "  Prints the distribution of classes (labels) in a given DataFrame.\n",
    "\n",
    "  This function calculates and displays the count and percentage of samples\n",
    "  for each unique class (label) in the specified DataFrame. It assumes the\n",
    "  DataFrame contains a column named 'label' representing the target variable.\n",
    "\n",
    "  Args:\n",
    "      df (pd.DataFrame): The input DataFrame containing the 'label' column.\n",
    "\n",
    "  Returns:\n",
    "      None: This function prints the class distribution but does not return\n",
    "            any value.\n",
    "  \"\"\"\n",
    "\n",
    "  # Get count for each label\n",
    "  label_count = df['label'].value_counts()\n",
    "\n",
    "  # Get total number of samples\n",
    "  total_samples = len(df)\n",
    "\n",
    "  # Count the number of items in each class\n",
    "  for i in range(len(label_count)):\n",
    "    label = label_count.index[i]\n",
    "    count = label_count.values[i]\n",
    "    percent = ((count / total_samples) * 100).round(2)\n",
    "    print(\"{:<20s}: {} or {}%\".format(label, count, percent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sZzXRo8Pb-yF",
    "outputId": "62e206b1-bb95-43de-fc67-4b09be907270"
   },
   "outputs": [],
   "source": [
    "get_classes_distribution(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490
    },
    "id": "oj1oZrvCb-yF",
    "outputId": "bfc81ecf-361a-46b6-b765-9df151b4e3a2"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Display bar chart for distribution of labels.\n",
    "\"\"\"\n",
    "\n",
    "# Count occurences of each label\n",
    "label_counts = df['label'].value_counts()\n",
    "\n",
    "# Plot the number of each labels\n",
    "plt.bar(label_counts.index, label_counts.values)\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Bar Chart for Label Counts')\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RrGPfta4b-yG"
   },
   "source": [
    "We can see the percentage/distribution of each emotion in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T6XfHUiab-yG"
   },
   "outputs": [],
   "source": [
    "def display_images(df, emotions):\n",
    "  \"\"\"\n",
    "  Displays a grid of sample images, one for each emotion, from the dataset.\n",
    "\n",
    "  This function selects one image per emotion from the DataFrame and displays\n",
    "  them in a grid layout. Each image is accompanied by its corresponding label\n",
    "  (emotion) as the title of the subplot.\n",
    "\n",
    "  Args:\n",
    "      df (pd.DataFrame): The input DataFrame containing image paths and labels.\n",
    "          It must include columns 'label' (emotion) and 'pth' (image path).\n",
    "      emotions (list): A list of emotion labels present in the dataset.\n",
    "\n",
    "  Returns:\n",
    "      None: This function displays the images but does not return any value.\n",
    "  \"\"\"\n",
    "\n",
    "  # Select one image per emotion\n",
    "  df_sample = df.groupby('label').first().reset_index()\n",
    "\n",
    "  fig, axs = plt.subplots(2, 4, sharey=True, num=None,\n",
    "                        figsize=(5, 5), dpi=80, edgecolor='k')\n",
    "  fig.suptitle(\"Sample Faces and Labels\")\n",
    "  axs = axs.flatten()\n",
    "\n",
    "  for idx, (ax, row) in enumerate(zip(axs, df_sample.iterrows())):\n",
    "    _, row = row  # Unpack index and row\n",
    "    image_path = kaggle_path + row['pth']\n",
    "    image = mpimg.imread(image_path)\n",
    "    ax.imshow(image)\n",
    "    ax.set_title(row['label'])\n",
    "    ax.axis('off')\n",
    "\n",
    "  plt.tight_layout()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "aCc3QKfxb-yH",
    "outputId": "ea426b4f-5373-4bbc-848d-7b6949cc29eb"
   },
   "outputs": [],
   "source": [
    "display_images(df, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qPWZWTgkb-yH"
   },
   "source": [
    "###Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eDPqaHL7b-yI"
   },
   "outputs": [],
   "source": [
    "def add_img_dim(df):\n",
    "  \"\"\"\n",
    "  Adds a new column to the DataFrame containing the dimensions (width, height)\n",
    "  of each image based on its file path.\n",
    "\n",
    "  Args:\n",
    "      df (pd.DataFrame): A DataFrame with an image file path column named 'pth'.\n",
    "                          Each path points to an image file.\n",
    "  Raises:\n",
    "      ValueError: If an image's dimensions are not (96, 96).\n",
    "\n",
    "  Returns:\n",
    "      None: Modifies the input DataFrame in place by adding a new column 'image_size',\n",
    "            which contains a tuple of (width, height) for each image.\n",
    "\n",
    "  Notes:\n",
    "      - The function uses the Python Imaging Library (PIL) to read image dimensions.\n",
    "      - Ensure that the paths in 'pth' are valid and accessible from the provided\n",
    "        `kaggle_path` directory.\n",
    "  \"\"\"\n",
    "\n",
    "  image_size = []\n",
    "\n",
    "  # Loop through each image path to get its dimensions\n",
    "  for path in df['pth']:\n",
    "      with Image.open(kaggle_path + path) as img:\n",
    "        width, height = img.size\n",
    "        image_size.append((width, height))\n",
    "\n",
    "  # Add the dimensions as a new column to df_train\n",
    "  df['image_size'] = image_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "PdKxoadMb-yI",
    "outputId": "42e8fde8-f72e-4d68-fc70-730d7ca4f278"
   },
   "outputs": [],
   "source": [
    "add_img_dim(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yzCTKCpib-yI"
   },
   "source": [
    "After adding the image_size column, we see each image has the same shape of (96,96). Thus we don't need to resize our images due to their uniform shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "16CJfARQb-yJ",
    "outputId": "c969ee13-e127-4096-ada4-543cf549644b"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Converts DataFrame data into NumPy arrays for model training.\n",
    "\n",
    "Assumptions:\n",
    "- The input DataFrame have the following structure:\n",
    "  - The first column contains the target labels.\n",
    "  - All other columns contain the features.\n",
    "\n",
    "Steps:\n",
    "1. Extracts feature data (all columns except the first) and converts them to NumPy arrays.\n",
    "2. Extracts target labels (first column) and converts them to NumPy arrays.\n",
    "3. Prints the shapes of the resulting training features (`x`) and target labels (`y`).\n",
    "\n",
    "The resulting arrays will have the following shapes:\n",
    "- x.shape == (number of rows in df, number of features).\n",
    "- y.shape == (number of rows in df,).\n",
    "\"\"\"\n",
    "\n",
    "x = np.array(df.iloc[:, 1:])\n",
    "y = np.array(df.loc[:, 'label'])\n",
    "\n",
    "print(\"x shape:\", x.shape,\n",
    "      \"y shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xCwJEgl2b-yJ"
   },
   "outputs": [],
   "source": [
    "def reshape_img_data(df, x):\n",
    "  \"\"\"\n",
    "  Reshapes image data from file paths into a NumPy array of pixel data.\n",
    "\n",
    "  Args:\n",
    "      df (pd.DataFrame): DataFrame containing a column 'pth' with file paths\n",
    "                          to the images.\n",
    "      x (np.ndarray): A placeholder variable for the resulting NumPy array.\n",
    "                      This parameter is overwritten during execution.\n",
    "\n",
    "  Returns:\n",
    "      np.ndarray: A NumPy array containing pixel data for all images in the DataFrame.\n",
    "                  The array shape is (num_images, height, width, channels), where:\n",
    "                  - `num_images` is the number of rows in the DataFrame.\n",
    "                  - `height` and `width` are the dimensions of the images.\n",
    "                  - `channels` is the number of color channels (3 for RGB).\n",
    "\n",
    "  Notes:\n",
    "      - Images are converted to RGB format regardless of their original color space.\n",
    "      - Ensure all images are of consistent size before running this function, or it will raise errors.\n",
    "      - Prints the shape of the resulting array for verification.\n",
    "  \"\"\"\n",
    "\n",
    "  image_data = []\n",
    "\n",
    "  # Loop through image paths and load pixel data\n",
    "  for path in df['pth']:\n",
    "    with Image.open(kaggle_path + path) as img:\n",
    "      # Convert to RGB or grayscale depending on the image\n",
    "      img = img.convert('RGB')\n",
    "      # Append image as an array\n",
    "      image_data.append(np.array(img))\n",
    "\n",
    "  # Convert list to array\n",
    "  x = np.array(image_data)\n",
    "\n",
    "  # Check the shape of the array\n",
    "  print(\"shape of x:\", x.shape)\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PKIq_Vy7b-yJ",
    "outputId": "c1a2beca-1fec-4388-ab14-039bb83dfc20"
   },
   "outputs": [],
   "source": [
    "x = reshape_img_data(df, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hf1GeHgxb-yK"
   },
   "source": [
    "Due to x's shape having a 3 in the last dimension, this means it has 3 color channels, RGB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "HibQaamcb-yK",
    "outputId": "be468345-feb2-45f4-fc7d-3fb5c554359c"
   },
   "outputs": [],
   "source": [
    "# Choose a random image index\n",
    "idx = np.random.randint(len(x))\n",
    "\n",
    "# Display the image and its corresponding label\n",
    "plt.imshow(x[idx])\n",
    "plt.title(f\"Label: {y[idx]}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "keLaOoCLb-yK"
   },
   "source": [
    "After the image is reshaped to an array with the pixel data, we can now show individual images from the training or test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vdxpgEn7b-yL"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Normalizes the pixel values of the image data.\n",
    "\n",
    "This step rescales the pixel values from the range [0, 255] to [0, 1] by converting\n",
    "the pixel values to `float32` and dividing by 255. This is commonly done in image\n",
    "preprocessing before feeding the data into a neural network, particularly convolutional\n",
    "neural networks (CNNs), to help the model learn faster and avoid large gradient values.\n",
    "\"\"\"\n",
    "x = x.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JEyXJizcb-yL",
    "outputId": "a0c6f77a-a955-4385-c24d-2b5b92b0b9a7"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Splits the training data into training and validation sets, performs one-hot\n",
    "encoding on the labels,and prints the shapes of the resulting datasets.\n",
    "\n",
    "1. Train-Test-Val Split:\n",
    "   - The function splits the `x` and `y` data into a new training\n",
    "      set and test set using an 80-20 split, then splits the 'x_train' and\n",
    "      'y_train' data into a new training and validation set using the same split.\n",
    "   - A fixed `random_state` is used for reproducibility.\n",
    "\n",
    "2. One-Hot Encoding:\n",
    "   - The labels (`y_train`, `y_val`, `y_test`) are one-hot encoded using\n",
    "      TensorFlow's `to_categorical` function.\n",
    "   - This is necessary for multi-class classification, where the output of the\n",
    "      model corresponds to the probability distribution over multiple classes.\n",
    "\"\"\"\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y,\n",
    "                                          test_size=0.2, random_state=42)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train,\n",
    "                                          test_size=0.2, random_state=42)\n",
    "\n",
    "num_classes = len(np.unique(y_train))\n",
    "\n",
    "# One-hot encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_val = label_encoder.transform(y_val)\n",
    "y_test = label_encoder.transform(y_test)\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_val = tf.keras.utils.to_categorical(y_val, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# Check the shapes of the new datasets\n",
    "print(\"x_train shape:\", x_train.shape, \"x_val shape:\", x_val.shape,\n",
    "      \"x_test shape:\", x_test.shape, \"y_train shape:\", y_train.shape,\n",
    "      \"y_val shape:\", y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7dW5oUcTb-yL"
   },
   "outputs": [],
   "source": [
    "\n",
    "model = models.Sequential([\n",
    "\n",
    "    # 1st Conv Block\n",
    "    layers.Conv2D (filters =32, kernel_size =3, strides = 1, padding ='same', activation='relu'),\n",
    "    layers.BatchNormalization(axis=-1),\n",
    "    layers.Conv2D (filters =32, kernel_size =3, strides = 1, padding ='same', activation='relu'),\n",
    "    layers.BatchNormalization(axis=-1),\n",
    "    layers.Conv2D (filters =32, kernel_size =3, strides = 1, padding ='same', activation='relu'),\n",
    "    layers.BatchNormalization(axis=-1),\n",
    "    layers.MaxPool2D(pool_size =2, strides =2, padding ='same'),\n",
    "    layers.Dropout(0.25),\n",
    "\n",
    "    # 2nd Conv Block\n",
    "    layers.Conv2D (filters =64, kernel_size =3, strides = 1, padding ='same', activation='relu'),\n",
    "    layers.BatchNormalization(axis=-1),\n",
    "    layers.Conv2D (filters =64, kernel_size =3, strides = 1, padding ='same', activation='relu'),\n",
    "    layers.BatchNormalization(axis=-1),\n",
    "    layers.Conv2D (filters =64, kernel_size =3, strides = 1, padding ='same', activation='relu'),\n",
    "    layers.BatchNormalization(axis=-1),\n",
    "    layers.MaxPool2D(pool_size =2, strides =2, padding ='same'),\n",
    "    layers.Dropout(0.25),\n",
    "\n",
    "    # 3rd Conv Block\n",
    "    layers.Conv2D (filters =128, kernel_size =3, strides = 1, padding ='same', activation='relu'),\n",
    "    layers.BatchNormalization(axis=-1),\n",
    "    layers.Conv2D (filters =128, kernel_size =3, strides = 1, padding ='same', activation='relu'),\n",
    "    layers.BatchNormalization(axis=-1),\n",
    "    layers.Conv2D (filters =128, kernel_size =3, strides = 1, padding ='same', activation='relu'),\n",
    "    layers.MaxPool2D(pool_size =2, strides =2, padding ='same'),\n",
    "    layers.Dropout(0.25),\n",
    "\n",
    "\n",
    "    # 4th Conv block\n",
    "    layers.Conv2D (filters =256, kernel_size =3, strides = 1 , padding ='same', activation='relu'),\n",
    "    layers.BatchNormalization(axis=-1),\n",
    "    layers.Conv2D (filters =256, kernel_size =3, strides = 1, padding ='same', activation='relu'),\n",
    "    layers.BatchNormalization(axis=-1),\n",
    "    layers.Conv2D (filters =256, kernel_size =3, strides = 1, padding ='same', activation='relu'),\n",
    "    layers.BatchNormalization(axis=-1),\n",
    "    layers.MaxPool2D(pool_size =2, strides =2, padding ='same'),\n",
    "    layers.Dropout(0.25),\n",
    "\n",
    "\n",
    "    # Fully connected layers\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(units = 1024, activation ='relu'),\n",
    "    layers.Dense(units = 1024, activation ='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(units = 8, activation ='softmax'),\n",
    "\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wLLE21eab-yM"
   },
   "outputs": [],
   "source": [
    "learning_rate = tf.Variable(0.001, trainable=False)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NeC9vozAb-yM",
    "outputId": "c61ca0c8-74d9-446c-d1e0-55144131b098"
   },
   "outputs": [],
   "source": [
    "def _is_distributed_dataset(dataset):\n",
    "    return isinstance(dataset, data_adapter.input_lib.DistributedDatasetSpec)\n",
    "\n",
    "data_adapter._is_distributed_dataset = _is_distributed_dataset\n",
    "history = model.fit(x_train, y_train, epochs=15, batch_size=32, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 569
    },
    "id": "UhxKeh7fYGoN",
    "outputId": "96e74eb0-1fc9-480c-d535-3c8a38d03417"
   },
   "outputs": [],
   "source": [
    "# Extract accuracy and validation accuracy\n",
    "training_accuracy = history.history['accuracy']\n",
    "validation_accuracy = history.history['val_accuracy']\n",
    "epochs = range(1, len(training_accuracy) + 1)  # Create a range for epochs\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(epochs, training_accuracy, label='Training Accuracy', marker='o')\n",
    "plt.plot(epochs, validation_accuracy, label='Validation Accuracy', marker='x')\n",
    "plt.title('Training Accuracy Over Epochs', fontsize=14)\n",
    "\n",
    "plt.xlabel('Epochs', fontsize=12)\n",
    "plt.ylabel('Accuracy', fontsize=12)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 569
    },
    "id": "HtXmXzgvYHez",
    "outputId": "20036a56-0338-42a8-cc21-6001ebf17707"
   },
   "outputs": [],
   "source": [
    "# Extract accuracy and validation accuracy\n",
    "training_accuracy = history.history['loss']\n",
    "validation_accuracy = history.history['val_loss']\n",
    "epochs = range(1, len(training_accuracy) + 1)  # Create a range for epochs\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(epochs, training_accuracy, label='Training Loss', marker='o')\n",
    "plt.plot(epochs, validation_accuracy, label='Validation Loss', marker='x')\n",
    "plt.title('Training Loss Over Epochs', fontsize=14)\n",
    "\n",
    "plt.xlabel('Epochs', fontsize=12)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OoAfFR2mb-yN",
    "outputId": "28b37727-90af-4025-8d14-562e8cc122f7"
   },
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "labels_list = ['sad', 'disgust', 'angry', 'neutral', 'fear', 'surprise', 'happy', 'contempt']\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "print(f\"Test Accuracy: {test_acc}\")\n",
    "print(classification_report(y_true, y_pred, target_names=labels_list, digits=4))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
